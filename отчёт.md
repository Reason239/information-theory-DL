Рекомендации по содержанию отчёта

* Отчёт должен быть написан чётко, в нём, помимо названия проекта и руководителя, нужно рассказать:
* в чём заключается глобальная задача на семестр (если проект командный, то для команды и для студента отдельно) ?
* каковы способы и сценарии использования результата?
* что именно студент успел сделать к моменту написания отчёта (здесь речь идёт именно про студента, а не про всех участников)?
* какие трудности возникали во время работы? что ещё нужно сделать до презентации результатов?
* какие технологии используются в работе? (если вы развиваете существующий проект, расскажите, как ваши наработки в него встраиваются)
* как организована работа и хватает ли общения с руководителями?
* привести ссылку на репозиторий с кодом.



#### Глобальная задача

Глобальными задачей является проверка результатов [статьи Тишби](https://arxiv.org/abs/1703.00810) более современными методами и для больших сетей. Вкратце, в статье утверждается, что если отложить слои $L_i$ нейросети на плоскости с осями "[взаимная информация]([https://ru.wikipedia.org/wiki/%D0%92%D0%B7%D0%B0%D0%B8%D0%BC%D0%BD%D0%B0%D1%8F_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%8F](https://ru.wikipedia.org/wiki/Взаимная_информация)) (MI) входа сети $X$ и $L_i$ - $I(X, L_i)$" и "взаимная информация $L_i$ и метки класса $Y$ - $I(L_i, Y)$ ", то по мере обучения сети картина будет вести себя определённым образом: сначала оба значения будут расти (fitting phase), а потом информация со входом будет падать (compression phase). То есть сначала сеть учится оставлять больше информации о входе и настоящей метке класса, а потом учится выбрасывать всю ненужную для определения класса информацию, содержащуюся во входе, чтобы добиться лучшей способности обобщать.  



К сожалению, статьи на эту тему весьма неоднозначны. Поэтому целью работы также было изучение разных статей для лучшего понимания общей картины и для выбора подходящих инструментов для анализа.



#### Просмотренные статьи

Список просмотренных статей можно увидеть на [GitHub]([https://github.com/Reason239/information-theory-DL/blob/master/%D0%9F%D0%BE%D0%BB%D0%B5%D0%B7%D0%BD%D1%8B%D0%B5%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8.md](https://github.com/Reason239/information-theory-DL/blob/master/Полезные ссылки.md)). В итоге было решено подробно остановиться на [статье под номером 2](http://openaccess.thecvf.com/content_ICCVW_2019/html/SDL-CV/Elad_Direct_Validation_of_the_Information_Bottleneck_Principle_for_Deep_Nets_ICCVW_2019_paper.html).



Во многих статьях [2, 4, 12, 13, 15] упоминается, что  если не добавлять в сеть никакого шума (явно или за счёт округления (биннинга) при подсчёте MI), то информация обращается в бесконечность, что делает постановку задачи некорректной. Статья [2] справляется с этой проблемой, добавляя в слои сети нормально распределённый шум, но только для оценивания информации.



Поскольку целью работы является оценка MI для реальных сетей, особый интерес представляли работы, предоставляющие инструменты для этого, особенно если возможно получить их код: [1, 2, 3, 8, 11, 18]. В случае [2] код удалось получить, связавшись с авторами статьи. Статья [7] выглядела очень интересно и была рекомендована соавтором Тишби, но получить код к ней не удалось.



В итоге, просмотрев эти статьи, я решил, что наиболее многообещающий инструмент для оценки MI описан в [2] - это вариант MINE [18], специально адаптированный для оценки информации в нейросетях. Статья про MINE утверждает, что их подход имеет преимущество над другими, поскольку он меньше подвержен потере точности при работе с высокими размерностями.



#### Что ещё было сделано

Был скачан код к статьям [1] и [2], установлены все нужные библиотеки для Python.



Код успешно запустился, в том числе не Google Colab (чтобы ускорить обучение сетей с помощью предоставленных там видеокарт). Было проведено несколько небольших экспериментов.



Код для рисования графиков для статьи Тишби был ужасно запутанным и перегруженным, поэтому он был переработан. Также были написаны вспомогательные функции, которые позволили брать вывод программы из статьи [2] и рисовать графики по нему. Код можно посмотреть [здесь](https://github.com/Reason239/information-theory-DL/tree/master/tishby_plots). Первые эксперименты произвели [такой график](https://github.com/Reason239/information-theory-DL/blob/master/tishby_plots/big1.jpg). Как 

