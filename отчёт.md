Рекомендации по содержанию отчёта

* Отчёт должен быть написан чётко, в нём, помимо названия проекта и руководителя, нужно рассказать:
* в чём заключается глобальная задача на семестр (если проект командный, то для команды и для студента отдельно) ?
* каковы способы и сценарии использования результата?
* что именно студент успел сделать к моменту написания отчёта (здесь речь идёт именно про студента, а не про всех участников)?
* какие трудности возникали во время работы? что ещё нужно сделать до презентации результатов?
* какие технологии используются в работе? (если вы развиваете существующий проект, расскажите, как ваши наработки в него встраиваются)
* как организована работа и хватает ли общения с руководителями?
* привести ссылку на репозиторий с кодом.



#### Глобальная задача

Глобальными задачей является проверка результатов [статьи Тишби](https://arxiv.org/abs/1703.00810) более современными методами и для больших сетей. Вкратце, в статье утверждается, что если отложить слои $L_i$ нейросети на плоскости с осями "[взаимная информация]([https://ru.wikipedia.org/wiki/%D0%92%D0%B7%D0%B0%D0%B8%D0%BC%D0%BD%D0%B0%D1%8F_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%8F](https://ru.wikipedia.org/wiki/Взаимная_информация)) (MI) входа сети $X$ и $L_i$ – $I(X, L_i)$" и "взаимная информация $L_i$ и метки класса $Y$ – $I(L_i, Y)$ ", то по мере обучения сети картина будет вести себя определённым образом: сначала оба значения будут расти (fitting phase), а потом информация со входом будет падать (compression phase). То есть сначала сеть учится оставлять больше информации о входе и настоящей метке класса, а потом учится выбрасывать всю ненужную для определения класса информацию, содержащуюся во входе, чтобы добиться лучшей обобщающей способности.  



К сожалению, статьи на эту тему весьма неоднозначны. Некоторые статьи утверждают, что результаты Тишби не воспроизводятся на сетях с другими функциями активации. Сама постановка вопроса также может отличаться от статьи к статье. Поэтому целью также является изучение разных работ для лучшего понимания общей картины и для выбора подходящих инструментов для анализа.



#### Просмотренные статьи

Список просмотренных статей можно увидеть на [GitHub](https://github.com/Reason239/information-theory-DL/blob/master/%D0%9F%D0%BE%D0%BB%D0%B5%D0%B7%D0%BD%D1%8B%D0%B5%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8.md). В итоге было решено подробно остановиться на [статье под номером 2](http://openaccess.thecvf.com/content_ICCVW_2019/html/SDL-CV/Elad_Direct_Validation_of_the_Information_Bottleneck_Principle_for_Deep_Nets_ICCVW_2019_paper.html).



Во многих статьях ([2, 4, 12, 13, 15]) упоминается, что  если не добавлять в сеть никакого шума (явно или за счёт округления (биннинга) при подсчёте MI), то информация обращается в бесконечность, что делает постановку задачи некорректной. Статья [2] справляется с этой проблемой, добавляя в слои сети нормально распределённый шум, но только для оценивания информации, а не во время тренировки.



Поскольку целью работы является оценка MI для реальных сетей, особый интерес представляли работы, предоставляющие инструменты для этого, особенно если возможно получить их код: [1, 2, 3, 8, 11, 18]. В случае [2] код удалось получить, связавшись с авторами статьи. Статья [7] выглядела очень интересно и была рекомендована соавтором Тишби, но получить код к ней не удалось.



В итоге, просмотрев эти статьи, я решил, что наиболее многообещающий инструмент для оценки MI описан в [2] - это вариант MINE ([18]), специально адаптированный для оценки информации в нейросетях. Статья про MINE утверждает, что их подход имеет преимущество над другими, поскольку он меньше подвержен потере точности при работе с высокими размерностями.



#### Работа с кодом

Был скачан код к статьям [1] и [2], установлены все нужные библиотеки для Python.



Код успешно запустился, в том числе на Google Colab (чтобы ускорить обучение сетей с помощью предоставленных там видеокарт). Было проведено несколько небольших экспериментов с чуть изменённым кодом к [2].



[Код](https://github.com/Reason239/information-theory-DL/blob/master/paper%20code/IDNNs-master/idnns/plots/plot_figures.py) для рисования графиков для статьи Тишби был ужасно запутанным и перегруженным, поэтому он [был переработан](https://github.com/Reason239/information-theory-DL/blob/master/tishby_plots/plots_refactored.py). Также была написана [вспомогательная функция](https://github.com/Reason239/information-theory-DL/blob/master/tishby_plots/plot_from_iccv.py), которая позволила брать [вывод программы из статьи [2]](https://github.com/Reason239/information-theory-DL/tree/master/tishby_plots/iccv%20output/colab1/Gamma_0_Activation_relu) и рисовать графики по нему. Первые эксперименты произвели [такой график](https://github.com/Reason239/information-theory-DL/blob/master/tishby_plots/big1.jpg). Выглядит он не очень хорошо, ещё есть к чему стремиться.



#### Дальнейшая работа

В дальнейшем планируется:



* Обработать [датасет]([https://github.com/Reason239/information-theory-DL/tree/master/paper%20code/IDNNs-master/data](https://github.com/Reason239/information-theory-DL/tree/master/paper code/IDNNs-master/data)) из статьи Тишби, конвертировав его из формата Matlab в более удобный. Воссоздать сеть из статьи Тишби, тренировавшуюся на этом датасете.
* Создать ещё один небольшой датасет таким образом, чтобы взаимную информацию между данными и меткой класса было просто вычислить. (например, используя смесь гауссианов и вычислив информацию явно) Использовать этот датасет для того, чтобы увидеть, насколько точны используемые методы оценки взаимной информации.  

* Переписать код статьи [2] в более удобном формате: на Keras и так, чтобы его было удобно использовать для проведения экспериментов. В исходном виде код пригоден только для архитектуры сети из статьи [2].
* Наконец, запустить полученный код на полученных датасетах и сетях (в том числе на свёрточных), чтобы увидеть, насколько полученная картина будет сходиться с предсказаниями Тишби. 

